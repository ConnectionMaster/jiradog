#!/usr/bin/python

"""Polls JIRA API and uploads to DataDog as a metric.

Args:
    -m|--metric:	String		Specify a metric name to run from the metrics.json file.
    -l|--list:		Boolean		List metric names from metrics.json.
    -n|--noop:		Boolean		Do everything except upload to Datadog,
              				print payload to stdin.
Returns:
    On standard run, returns nothing.
"""

import argparse
import sys
import json
import urllib
import re
import time
import logging
import os
from pprint import pprint
import jinja2
import requests
from datadog import initialize, api

## Data providers
class JiraProvider(object):
    """This creates the paginated URLS (multiple urls to hit because the total results exceed the
    maximum allowable returned results) and calls the API, returning results.

    Args:
        provider_config:	Dictionary, the part of the config that defines the data provider source,
                        	and JQL query string.
        project:		String, the JIRA project that will be put into the templatized JQL query
                		string.
        MAX_RESULTS:		Integer, currently hard set at 100, maximum supported by JIRA.
        username:		String, the username of the user who is being used to access the API over
                 		basic HTTP auth.
        password:		String, password of the above user.
        server:			String, JIRA server url instance; where to hit the API.

    Returns:
        A list of dictionaries that are the JSON objects returned by the API calls. All URLS are
        generated by the paginate function.
    """

    @classmethod
    def issue_filter(cls, paginated_list, filter_jinja2):
        """Filters issues with a jinja2 syntax if/then statement.

        Args:
            paginated_list	List	Of dictionaries of lists of issues returned from paginated JIRA
                          		API calls.
            filter_jinja2:	String	jinja2 syntax if/then statement for filterin, found in the
                          		metric config.

        Returns:
            List of dictionaries of lists of issues.
        """
        filter_jinja2_regex = re.search("(^{% if )(.*)( )(~)( )(.*)( %}$)", filter_jinja2)
        fields = filter_jinja2_regex.group(2).split('.')
        operator = filter_jinja2_regex.group(4)
        value = filter_jinja2_regex.group(6)
        issue_list = []
        issues = []
        issue = None
        for issue in paginated_list:
            if len(fields) == 5:
                regex_result = re.search(value,
                                         issue[fields[1]][fields[2]][int(fields[3])][fields[4]])
            elif len(fields) == 4:
                regex_result = re.search(value,
                                         issue[fields[1]][fields[2]][fields[3]])
            elif len(fields) == 3:
                regex_result = re.search(value,
                                         issue[fields[1]][fields[2]])
            elif len(fields) == 2:
                regex_result = re.search(value,
                                         issue[fields[1]])

            if operator == "~":
                if isinstance(regex_result, type(None)) != True:
                    issues.append(issue)
        issue_list.append({'issues': issues})
        return issue_list

    @classmethod
    def paginate(cls, base_api_url, total, max_results_per_page):
        """Create a list of JIRA API search urls appended with '&startAt=N' in order to get all
        results from a JQL query.

        Args:
            base_api_url:	String		The specified API url, given by the provide
                         			function, derived from the jql key in the
                                      		metric config file.
            total:		Integer		Total number of issues, pulled from the original
                  				API call.
            max_results_per_page:	Integer		Currently hard set at 100, maximum supported by
                        			JIRA.

        Returns:
            A list of urls, with the appended '&startAt=N' that, when looped, will pull all JQL
            search results.
        """
        paginations = []
        start_at = max_results_per_page
        while int(start_at) < int(total):
            paginations.append(base_api_url + '&startAt=' + str(start_at))
            start_at = int(start_at) + int(max_results_per_page)
        return paginations

    def provide(self, provider_config, project, max_results_per_page):
        """Makes API calls using the JIRA API, version 2, search.

        Args:
            provider_config:	Dictionary	The part of the config that defines the data
                            			provider source, and JQL query string.
            project:		String		The JIRA project that will be put into the
                    				templatized JQL query string.
            max_results_per_page:	Integer		Currently hard set at 100, maximum supported
                        			by JIRA.

        Returns:
            A list of dictionaries that are the JSON objects returned by the API calls. All URLS
            are generated by the paginate function.
        """
        jql_rendered = jinja2.Template(provider_config["jql"]).render(project=project)
        jql_url_encoded = urllib.quote(jql_rendered)
        jira_api_call_url = API_ENDPOINT + jql_url_encoded + '&maxResults=' + max_results_per_page
        jira_api_response = json.loads(requests.get(jira_api_call_url,
                                                    headers=HEADERS,
                                                    auth=(API_USERNAME, API_PASSWORD)).text)
        jira_api_responses = [jira_api_response]
        for url in self.paginate(jira_api_call_url,
                                 jira_api_response['total'],
                                 max_results_per_page):
            jira_api_response = requests.get(url,
                                             headers=HEADERS,
                                             auth=(API_USERNAME, API_PASSWORD))
            jira_api_responses.append(json.loads(jira_api_response.text))
        filter_jinja2 = provider_config.get('filter', False)

        issues = []
        for page in jira_api_responses:
            for issue in page['issues']:
                issues.append(issue)

        if filter_jinja2 != False:
            paginated_list = self.issue_filter(issues, provider_config['filter'])
        else:
            paginated_list = issues

        return paginated_list

def constant_provider_provide(data, project):
    """Retrieves and retunrs explicit data hard-coded into the metric config file.

    Args:
        data:			Dictionary	Data from the metric config file.
        project:		String		The JIRA project; used to get data from the
                				imported dictionary.
        null_max_results:	Integer		NULL metric, to allow generalized usaged. Unused
                         			by this function.

    Returns:
        A single value from a hard coded dictionary included the in the metric config file.
    """
    return data["data"][project]

def direct(provider_config, project):
    """Gets a single number from JIRA and submits it to DataDog.

    Args:
        provider_config:	Dictionary	Pulled from the metric config, contains source,
                          			and arguments.
        project:		String		The jira project being injected into the
                  				templatized JQL query string.
    Returns:
        Integer of the results from JIRA API requests.
    """
    if provider_config['source'] == 'jira':
        logging.info('data provider: ' + provider_config['source'])
        paginated_list = JiraProvider().provide(provider_config, project, MAX_RESULTS)
        running_total = []
        for result in paginated_list:
            running_total.append(FUNCTION_MAP[provider_config['method']](result, None))
        return sum(running_total)

## post-processing methods
def average(numerator, denominator):
    """Finds the average of 2 numbers.

    Args:
        numerator:	Integer		The numerator, found using one of the data providers.
        denominator:	Integer		The denominator, found using one of the data providers.

    Returns:
        Integer of the resulting division. If the denominator is 0, sets the returned value as 0.
    """
    if denominator != 0:
        mean = float(numerator)/float(denominator)
    else:
        mean = 0
    return mean

def mean_time_between_statuses(first_date, second_date):
    """Calculates the length of time between two statuses

    Args:
        first_date:	String	A simple string of the start date in the format '%Y-%m-%dT%H:%M:%S'
        second_date:	String	A simple string of the end date in the format '%Y-%m-%dT%H:%M:%S'

    Returns:
        Floating point number in days
    """
    first_date_sec = time.strptime(first_date.split('.')[0], '%Y-%m-%dT%H:%M:%S')
    second_date_sec = time.strptime(second_date.split('.')[0], '%Y-%m-%dT%H:%M:%S')
    return (time.mktime(second_date_sec) - time.mktime(first_date_sec)) / 60 / 60 / 24

## data provider methods
def ticket_count(paginated_list):
    """Gets the count of issues from a JQL query result.

    Args:
        result:		List	A single page from an API call.

    Returns:
        Integer of the number of issues counted.
    """
    total_issues = 0
    total_issues = len(paginated_list)
    return total_issues

def custom_field_sum(result, custom_field):
    """Sums custom field values together.

    Args:
        result:		Dictionary	The result from a JIRA JQL query.
        custom_field:	String		The custom field to sum.

    Returns:
        Integer of the sum of all the found values of the custom_field.
    """
    cf_sum = 0
    for issue in result['issues']:
        if issue['fields'][custom_field] is None:
            cf_sum = int(cf_sum) + 2
        else:
            cf_sum = int(cf_sum) + int(issue['fields'][custom_field])
        return cf_sum

def get_number_average(provider_config, position, project):
    """Gets and returns either numerator or denominator for average method from metric config file
    and data provider

    Args:
        provider_config:	Dictionary	Pulled from the metric config, contains source,
                        			and arguments.
        position:		String		Indicates if this is the numerator or denominator
        project:		String		The jira project being injected into the
                				templatized JQL query string.

    Returns:
        A float to act as the numerator.
    """
    if provider_config['source'] == 'jira':
        logging.info('data provider: ' + provider_config['source'])
        paginated_list = JiraProvider().provide(provider_config, project, MAX_RESULTS)
        running_total = []
        for result in paginated_list:
            if provider_config['method'] == 'ticket_count':
                running_total.append(ticket_count(result))
            elif provider_config['method'] == 'custom_field_sum':
                running_total.append(custom_field_sum(result, provider_config['field']))
        number = sum(running_total)
        logging.info(position + ': ' + str(number))
    elif provider_config['source'] == 'constant':
        logging.info('data provider: ' + provider_config['source'])
        number = constant_provider_provide(provider_config, project)
        logging.info(position + ': ' + str(number))
    else:
        logging.error('avg_' +
                      position +
                      ' ' +
                      'data provider is set to an unknown value: ' +
                      provider_config['source'])
        sys.exit(1)
    return number

def load_metric_file(metric_file, is_args_metric_set):
    """Created python dictionary from metrics.json file.

    Args:
        metric_file:		String		The file location for metrics.json.
        is_args_metric_set:	Boolean		Specifies if the entire file is to be loaded
                           			(False) or a single metric by name (True)

    Returns:
        Dictionary of the values in the metrics.json file.
    """
    with open(metric_file) as metric_file_loaded:
        metric_file_full = json.load(metric_file_loaded)
    if is_args_metric_set:
        for metric_config in metric_file_full:
            if metric_config['metric_name'] == is_args_metric_set:
                metric_file_full = [metric_config]
    return metric_file_full

def main():
    """Main function, calls all other functions.

    Returns:
        In a standard run, no output.
    """
    parser = argparse.ArgumentParser()
    parser.add_argument('-m', '--metric',
                        metavar='METRIC',
                        help='Run only the specific metric')
    parser.add_argument('-l', '--list',
                        help='Get a list of defined metrics',
                        action='store_true')
    parser.add_argument('-n', '--noop',
                        help='Outputs the payload to stdin, does not upload',
                        action='store_true')
    parser.add_argument('-d', '--describe',
                        metavar='METRIC',
                        help='Prints the configuration block for the specified metric')
    parser.add_argument('-v', '--version',
                        help='Display the version number',
                        action='store_true')

    args = parser.parse_args()

    logging.info('api configuration set')

    # Setting up DataDog SDK
    initialize(**CONFIG_DATA_LOADED['datadog'])
    logging.info('initializated datadog SDK')

    # Loads the metric configuration file
    metric_file_full = load_metric_file(METRIC_JSON, args.metric)

    if args.list:
        for metric in metric_file_full:
            print metric['metric_name']
        sys.exit(0)

    if args.describe:
        for metric in metric_file_full:
            if metric['metric_name'] == args.describe:
                pprint(metric)
        sys.exit(0)

    if args.version:
        print os.path.basename(__file__) + ' 1.0'
        sys.exit(0)

    logging.info('loaded metric config')

    # Loops through list of metrics defined in a single file
    for metric_data_loaded in metric_file_full:
        # Loop over specified projects in the metric config file.
        project = None
        for project in metric_data_loaded['projects']:
            logging.info('project: ' + project)
            if metric_data_loaded['method'] == 'average':
                ## Find the average from data providers.
                logging.info('method: ' + metric_data_loaded['method'])
                points = average(get_number_average(metric_data_loaded['avg_numerator'],
                                                    'numerator',
                                                    project),
                                 get_number_average(metric_data_loaded['avg_denominator'],
                                                    'denominator',
                                                    project))
            elif metric_data_loaded['method'] == 'mean_time_between_statuses':
                ## Find the average time between specified statuses.
                logging.info('method: ' + metric_data_loaded['method'])

                date_diff_days = []
                paginated_list = JiraProvider().provide(metric_data_loaded['issues'],
                                                        project,
                                                        MAX_RESULTS)
                if paginated_list:
                    for issue in paginated_list:
                        m_t = mean_time_between_statuses(issue['fields']['created'],
                                                         issue['fields']['updated'])
                        date_diff_days.append(m_t)
                    total_time_between_statuses = sum(date_diff_days)
                    total_issue_count = ticket_count(paginated_list)
                else:
                    total_time_between_statuses = 0
                    total_issue_count = 0

                points = average(total_time_between_statuses, total_issue_count)

            elif metric_data_loaded['method'] == 'direct':
                points = direct(metric_data_loaded['issues'], project)

        ## Construct payload for upload
            metric_data = {
                'metric': metric_data_loaded['metric_name'],
                'points': (time.time(), points),
                'tags': ["jira_project:%s" % project]
                }
            PAYLOAD.append(metric_data)

        logging.info('payload: ' + str(PAYLOAD))

    if args.noop:
        pprint(PAYLOAD)
    else:
        # Upload to DataDog
        api.Metric.send(PAYLOAD)
        logging.info('uploaded to DataDog')

if __name__ == "__main__":
    # Setting important variables, all static.
    FUNCTION_MAP = {
        'average': average,
        'mean_time_between_statuses': mean_time_between_statuses,
        'ticket_count': ticket_count,
        'custom_field_sum': custom_field_sum,
        'direct': direct
        }
    MAX_RESULTS = str(100)
    CONFIG_FILE = 'config.json'
    HEADERS = {'Content-type': 'application/json'}
    PAYLOAD = []

    # Loads the configuration file for the script.
    with open(CONFIG_FILE) as config_data_file:
        CONFIG_DATA_LOADED = json.load(config_data_file)

    # Set important information scraped from the configuration file.
    API_USERNAME = CONFIG_DATA_LOADED['jira']['username']
    API_PASSWORD = CONFIG_DATA_LOADED['jira']['password']
    API_URL = CONFIG_DATA_LOADED['jira']['server']
    API_ENDPOINT = API_URL + '/rest/api/2/search?jql='
    LOG_FILE = CONFIG_DATA_LOADED['local']['log_file']
    METRIC_JSON = CONFIG_DATA_LOADED['local']['metric_file']

    # Set logging config
    LOGGING_LEVELS = {
        'info': logging.INFO,
        'debug': logging.DEBUG,
        'warning': logging.WARNING,
        'error': logging.ERROR,
        'critical': logging.CRITICAL
        }
    LOGGING_LEVEL = LOGGING_LEVELS.get('debug', logging.NOTSET)
    logging.basicConfig(filename=LOG_FILE,
                        format='%(asctime)s %(levelname)s %(message)s',
                        level=LOGGING_LEVEL)

    # Executing script
    main()
